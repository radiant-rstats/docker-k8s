{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27730 Jps\n"
     ]
    }
   ],
   "source": [
    "# check if HDFS is running\n",
    "jps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting HDFS ...\n"
     ]
    }
   ],
   "source": [
    "# if HDFS is not running, start the HDFS services\n",
    "/opt/hadoop/start-dfs.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28067 SecondaryNameNode\n",
      "28165 Jps\n",
      "27803 NameNode\n",
      "27933 DataNode\n"
     ]
    }
   ],
   "source": [
    "# check Java processes running\n",
    "jps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# checking contents of HDFS as root \"/\"\n",
    "hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create a directory on HDFS\n",
    "hdfs dfs -mkdir /Demo1-HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwxr-xr-x   - jovyan supergroup          0 2024-12-26 11:44 /Demo1-HDFS\n"
     ]
    }
   ],
   "source": [
    "# new directory should be visible now\n",
    "hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MGTA466-S1-2-HandsOn.pdf  check-hdfs-setup.ipynb\n",
      "Shakespeare.txt\t\t  hdfs-handson-test.ipynb\n"
     ]
    }
   ],
   "source": [
    "# check that the Shakespeare file is available in your current directory\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# copy data to HDFS and verify file is there\n",
    "hdfs dfs -copyFromLocal Shakespeare.txt /Demo1-HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   1 jovyan supergroup    5777367 2024-12-26 11:44 /Demo1-HDFS/Shakespeare.txt\n"
     ]
    }
   ],
   "source": [
    "# verify that file is not in the new directory on HDFS\n",
    "hdfs dfs -ls /Demo1-HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Project Gutenberg’s The Complete Works of William Shakespeare, by William\n",
      "Shakespeare\n",
      "\n",
      "This eBook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever.  You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this eBook or online at\n",
      "www.gutenberg.org.  If you are not located in the United States, you’ll\n",
      "have to check the laws of the country where you are located before using\n",
      "cat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "# see first few lines of Shakespeare.txt on HDFS\n",
    "hdfs dfs -cat /Demo1-HDFS/Shakespeare.txt | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# make a copy of the file on HDFS\n",
    "hdfs dfs -cp /Demo1-HDFS/Shakespeare.txt /Demo1-HDFS/ShakespeareNew.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   1 jovyan supergroup    5777367 2024-12-26 11:44 /Demo1-HDFS/Shakespeare.txt\n",
      "-rw-r--r--   1 jovyan supergroup    5777367 2024-12-26 11:44 /Demo1-HDFS/ShakespeareNew.txt\n"
     ]
    }
   ],
   "source": [
    "# list content of Demo1-HDFS directory\n",
    "hdfs dfs -ls /Demo1-HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Project Gutenberg’s The Complete Works of William Shakespeare, by William\n",
      "Shakespeare\n",
      "\n",
      "This eBook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever.  You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this eBook or online at\n",
      "www.gutenberg.org.  If you are not located in the United States, you’ll\n",
      "have to check the laws of the country where you are located before using\n",
      "cat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "# check the contents of the new file\n",
    "hdfs dfs -cat /Demo1-HDFS/ShakespeareNew.txt  | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# copy results from HDFS to local file system\n",
    "hdfs dfs -copyToLocal /Demo1-HDFS/ShakespeareNew.txt ShakespeareNew.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MGTA466-S1-2-HandsOn.pdf  ShakespeareNew.txt\t  hdfs-handson-test.ipynb\n",
      "Shakespeare.txt\t\t  check-hdfs-setup.ipynb\n"
     ]
    }
   ],
   "source": [
    "# should see the 2 Shakespeare files in your local folder\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# compare the two Shakespeare files on local system\n",
    "diff Shakespeare.txt ShakespeareNew.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Project Gutenberg’s The Complete Works of William Shakespeare, by William\n",
      "Shakespeare\n",
      "\n",
      "This eBook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever.  You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this eBook or online at\n",
      "www.gutenberg.org.  If you are not located in the United States, you’ll\n",
      "have to check the laws of the country where you are located before using\n"
     ]
    }
   ],
   "source": [
    "# check contents of file copied to local system\n",
    "head ShakespeareNew.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# remove copied file from local system\n",
    "rm ShakespeareNew.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping HDFS ...\n"
     ]
    }
   ],
   "source": [
    "# stop the HDFS services\n",
    "/opt/hadoop/stop-dfs.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29692 Jps\n"
     ]
    }
   ],
   "source": [
    "# check if HDFS is running\n",
    "jps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting HDFS ...\n"
     ]
    }
   ],
   "source": [
    "# stat HDFS back up\n",
    "/opt/hadoop/start-dfs.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   1 jovyan supergroup    5777367 2024-12-26 11:44 /Demo1-HDFS/Shakespeare.txt\n",
      "-rw-r--r--   1 jovyan supergroup    5777367 2024-12-26 11:44 /Demo1-HDFS/ShakespeareNew.txt\n"
     ]
    }
   ],
   "source": [
    "# list content of Demo1-HDFS directory\n",
    "# files should still be there\n",
    "# note that running /opt/hadoop/init-hdfs.sh will remove all files from HDFS\n",
    "hdfs dfs -ls /Demo1-HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping HDFS ...\n",
      "2024-12-26 11:45:21,969 INFO namenode.NameNode: STARTUP_MSG: \n",
      "/************************************************************\n",
      "STARTUP_MSG: Starting NameNode\n",
      "STARTUP_MSG:   host = 969e72aac914/172.18.0.2\n",
      "STARTUP_MSG:   args = [-format, -force]\n",
      "STARTUP_MSG:   version = 3.3.4\n",
      "STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/opt/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/opt/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/opt/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/opt/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/opt/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/opt/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/opt/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/opt/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/opt/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/opt/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/opt/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/opt/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/opt/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/opt/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/opt/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/opt/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/opt/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar\n",
      "STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z\n",
      "STARTUP_MSG:   java = 17.0.13\n",
      "************************************************************/\n",
      "2024-12-26 11:45:21,979 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\n",
      "2024-12-26 11:45:22,017 INFO namenode.NameNode: createNameNode [-format, -force]\n",
      "2024-12-26 11:45:22,211 INFO namenode.NameNode: Formatting using clusterid: CID-beec925e-dc37-460b-a2cf-91c116ead4c8\n",
      "2024-12-26 11:45:22,222 INFO namenode.FSEditLog: Edit logging is async:true\n",
      "2024-12-26 11:45:22,233 INFO namenode.FSNamesystem: KeyProvider: null\n",
      "2024-12-26 11:45:22,234 INFO namenode.FSNamesystem: fsLock is fair: true\n",
      "2024-12-26 11:45:22,234 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\n",
      "2024-12-26 11:45:22,243 INFO namenode.FSNamesystem: fsOwner                = jovyan (auth:SIMPLE)\n",
      "2024-12-26 11:45:22,243 INFO namenode.FSNamesystem: supergroup             = supergroup\n",
      "2024-12-26 11:45:22,244 INFO namenode.FSNamesystem: isPermissionEnabled    = true\n",
      "2024-12-26 11:45:22,244 INFO namenode.FSNamesystem: isStoragePolicyEnabled = true\n",
      "2024-12-26 11:45:22,244 INFO namenode.FSNamesystem: HA Enabled: false\n",
      "2024-12-26 11:45:22,261 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\n",
      "2024-12-26 11:45:22,266 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\n",
      "2024-12-26 11:45:22,266 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\n",
      "2024-12-26 11:45:22,267 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\n",
      "2024-12-26 11:45:22,267 INFO blockmanagement.BlockManager: The block deletion will start around 2024 Dec 26 11:45:22\n",
      "2024-12-26 11:45:22,268 INFO util.GSet: Computing capacity for map BlocksMap\n",
      "2024-12-26 11:45:22,268 INFO util.GSet: VM type       = 64-bit\n",
      "2024-12-26 11:45:22,268 INFO util.GSet: 2.0% max memory 7.8 GB = 160.2 MB\n",
      "2024-12-26 11:45:22,268 INFO util.GSet: capacity      = 2^24 = 16777216 entries\n",
      "2024-12-26 11:45:22,273 INFO blockmanagement.BlockManager: Storage policy satisfier is disabled\n",
      "2024-12-26 11:45:22,273 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\n",
      "2024-12-26 11:45:22,275 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.999\n",
      "2024-12-26 11:45:22,275 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\n",
      "2024-12-26 11:45:22,275 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\n",
      "2024-12-26 11:45:22,275 INFO blockmanagement.BlockManager: defaultReplication         = 1\n",
      "2024-12-26 11:45:22,275 INFO blockmanagement.BlockManager: maxReplication             = 512\n",
      "2024-12-26 11:45:22,276 INFO blockmanagement.BlockManager: minReplication             = 1\n",
      "2024-12-26 11:45:22,276 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\n",
      "2024-12-26 11:45:22,276 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\n",
      "2024-12-26 11:45:22,276 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\n",
      "2024-12-26 11:45:22,276 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\n",
      "2024-12-26 11:45:22,283 INFO namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911\n",
      "2024-12-26 11:45:22,283 INFO namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215\n",
      "2024-12-26 11:45:22,283 INFO namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215\n",
      "2024-12-26 11:45:22,284 INFO namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215\n",
      "2024-12-26 11:45:22,288 INFO util.GSet: Computing capacity for map INodeMap\n",
      "2024-12-26 11:45:22,288 INFO util.GSet: VM type       = 64-bit\n",
      "2024-12-26 11:45:22,289 INFO util.GSet: 1.0% max memory 7.8 GB = 80.1 MB\n",
      "2024-12-26 11:45:22,289 INFO util.GSet: capacity      = 2^23 = 8388608 entries\n",
      "2024-12-26 11:45:22,289 INFO namenode.FSDirectory: ACLs enabled? true\n",
      "2024-12-26 11:45:22,289 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\n",
      "2024-12-26 11:45:22,289 INFO namenode.FSDirectory: XAttrs enabled? true\n",
      "2024-12-26 11:45:22,290 INFO namenode.NameNode: Caching file names occurring more than 10 times\n",
      "2024-12-26 11:45:22,291 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536\n",
      "2024-12-26 11:45:22,292 INFO snapshot.SnapshotManager: SkipList is disabled\n",
      "2024-12-26 11:45:22,294 INFO util.GSet: Computing capacity for map cachedBlocks\n",
      "2024-12-26 11:45:22,294 INFO util.GSet: VM type       = 64-bit\n",
      "2024-12-26 11:45:22,294 INFO util.GSet: 0.25% max memory 7.8 GB = 20.0 MB\n",
      "2024-12-26 11:45:22,294 INFO util.GSet: capacity      = 2^21 = 2097152 entries\n",
      "2024-12-26 11:45:22,297 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\n",
      "2024-12-26 11:45:22,297 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\n",
      "2024-12-26 11:45:22,298 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\n",
      "2024-12-26 11:45:22,300 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\n",
      "2024-12-26 11:45:22,300 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\n",
      "2024-12-26 11:45:22,301 INFO util.GSet: Computing capacity for map NameNodeRetryCache\n",
      "2024-12-26 11:45:22,301 INFO util.GSet: VM type       = 64-bit\n",
      "2024-12-26 11:45:22,302 INFO util.GSet: 0.029999999329447746% max memory 7.8 GB = 2.4 MB\n",
      "2024-12-26 11:45:22,302 INFO util.GSet: capacity      = 2^18 = 262144 entries\n",
      "Data exists in Storage Directory root= /tmp/hadoop-jovyan/dfs/name; location= null. Formatting anyway.\n",
      "2024-12-26 11:45:22,318 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1968560427-172.18.0.2-1735242322313\n",
      "2024-12-26 11:45:22,318 INFO common.Storage: Will remove files: [/tmp/hadoop-jovyan/dfs/name/current/edits_0000000000000000002-0000000000000000016, /tmp/hadoop-jovyan/dfs/name/current/fsimage_0000000000000000000.md5, /tmp/hadoop-jovyan/dfs/name/current/fsimage_0000000000000000000, /tmp/hadoop-jovyan/dfs/name/current/edits_inprogress_0000000000000000018, /tmp/hadoop-jovyan/dfs/name/current/seen_txid, /tmp/hadoop-jovyan/dfs/name/current/VERSION, /tmp/hadoop-jovyan/dfs/name/current/edits_0000000000000000017-0000000000000000017, /tmp/hadoop-jovyan/dfs/name/current/edits_0000000000000000001-0000000000000000001]\n",
      "2024-12-26 11:45:22,331 INFO common.Storage: Storage directory /tmp/hadoop-jovyan/dfs/name has been successfully formatted.\n",
      "2024-12-26 11:45:22,344 INFO namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jovyan/dfs/name/current/fsimage.ckpt_0000000000000000000 using no compression\n",
      "2024-12-26 11:45:22,389 INFO namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jovyan/dfs/name/current/fsimage.ckpt_0000000000000000000 of size 401 bytes saved in 0 seconds .\n",
      "2024-12-26 11:45:22,393 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\n",
      "2024-12-26 11:45:22,410 INFO namenode.FSNamesystem: Stopping services started for active state\n",
      "2024-12-26 11:45:22,410 INFO namenode.FSNamesystem: Stopping services started for standby state\n",
      "2024-12-26 11:45:22,413 INFO namenode.FSImage: FSImageSaver clean checkpoint: txid=0 when meet shutdown.\n",
      "2024-12-26 11:45:22,413 INFO namenode.NameNode: SHUTDOWN_MSG: \n",
      "/************************************************************\n",
      "SHUTDOWN_MSG: Shutting down NameNode at 969e72aac914/172.18.0.2\n",
      "************************************************************/\n",
      "Starting HDFS ...\n"
     ]
    }
   ],
   "source": [
    "# stop and re-initialize the HDFS services\n",
    "/opt/hadoop/stop-dfs.sh\n",
    "/opt/hadoop/init-dfs.sh\n",
    "/opt/hadoop/start-dfs.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# list content of HDFS directory\n",
    "hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping HDFS ...\n"
     ]
    }
   ],
   "source": [
    "# make sure to stop the HDFS services when you are done\n",
    "/opt/hadoop/stop-dfs.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
